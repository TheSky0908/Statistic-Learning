---
title: "Statistic Learning Assignment 2"
author: "12111603 Tan Zhiheng"
date: "2023-10-30"
output:
  html_document: 
    toc: yes
    theme: spacelab
  

---

<style>
body {
  font-family: 'Times New Roman', sans-serif;
  font-size: 18px;
  color: black;
  
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 10 in Section 4.7 of ISLR

### (a)

```{r}

library("ISLR")
library("car")
data(Weekly)
summary(Weekly)
cor(Weekly[,-9])
```

As one would expect, the correlations between the lag variables and today’s returns are close to zero. In other words, there appears to be little
correlation between today’s returns and previous days’ returns. The only
substantial correlation is between Year and Volume, which is approximately 0.84. By plotting the data we see that Volume is increasing over time. In other words, the average number of shares traded weekly increased from 1990 to 2010.

```{r error=FALSE, warning=FALSE}
scatterplotMatrix(Weekly[,-9],spread=FALSE, lty.smooth=2,main="Scatter Plot Matrix")

```

From the scatter plot matrix we can discover that there is little linear relationship between today's returns and previous days' returns, which is consistent with the conclusion we drew to previously. Then we plot Volume with time.

```{r}
plot(Weekly$Volume, main = "Volume with Time")

```

Thus, From the plot we can figure out that there is an increasing trend pattern between Volume and Year.


### (b)

```{r}
log.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
               family = binomial(), data = Weekly)
summary(log.fit)


```

We maintain that the Intercept and Lag2 is significant. The positive coefficient of Lag2 suggests that if the market had a positive return the day before yesterday, then it is more likely to go up today.


### (c)

```{r}
glm.probs <- predict(log.fit,type = "response")
contrasts(Weekly$Direction)

glm.pred <- rep("Down", 1089)
glm.pred[glm.probs>0.5] <- "Up"
```

The confusion matrix is as follows.

```{r}
table(glm.pred, Weekly$Direction)
```

The overall fraction of correct predictions is computed as follows.

```{r}
mean(glm.pred == Weekly$Direction)
```

- In this case, logistic regression correctly predicted the movement of the market $56.1\%$ of the time. The diagonal elements of the confusion matrix indicate correct predictions, while the off-diagonals represent incorrect predictions. Hence our model correctly predicted that the market would go up on 557 days and that it would go down on 54 days, for a total of 557 + 54 = 611 correct predictions. In other words, there are 48 sample points which should have been classified as "Up" but be wrongly predicted as "Down" and 430 points which should have been classified as "Down" but be wrongly predicted as "Up".

- TPR: 557/(557+48) = 0.92
- FPR: 430/(430+54) = 0.89

### (d)

```{r}
train <- subset(Weekly, Year %in% 1990:2008)
test <- subset(Weekly, Year %in% c(2009,2010))


log.fit2 <- glm(Direction ~ Lag2, data = train, family = binomial())
glm.probs2 <- predict(log.fit2, test, type = "response")
glm.pred2 <- rep("Down", nrow(test))
glm.pred2[glm.probs2 > 0.5] <- "Up"
```

The confusion matrix is as follows.

```{r}
table(glm.pred2,test$Direction)
```

The overall fraction of correct predictions is computed as follows.

```{r}
mean(glm.pred2 == test$Direction)

```


### (e)

```{r}
library(MASS)
lda.fit <- lda(Direction ~ Lag2, data = train)
lda.fit
plot(lda.fit)


preb <- predict(lda.fit, test, type = "response")
names(preb)
lda.class <- preb$class
```

The confusion matrix is as follows.

```{r}
table(lda.class, test$Direction)
```

The overall fraction of correct predictions is computed as follows.

```{r}
mean(lda.class == test$Direction)
```


### (f)

```{r}
qda.fit <- qda(Direction ~ Lag2, data = train)
qda.fit



preb <- predict(qda.fit, test, type = "response")
names(preb)
qda.class <- preb$class
```

The confusion matrix is as follows.

```{r}
table(qda.class, test$Direction)
```


The overall fraction of correct predictions is computed as follows.

```{r}
mean(qda.class == test$Direction)

```


### (g)
```{r}
library(class)
train.X <- cbind(train$Lag2)
test.X <- cbind(test$Lag2)
train.Y <- train$Direction
set.seed(1)
knn.pred <- knn(train.X,test.X,train.Y,k = 1)
```

The confusion matrix is as follows.

```{r}
table(knn.pred, test$Direction)
```

The overall fraction of correct predictions is computed as follows.

```{r}
mean(knn.pred == test$Direction)

```

### (h)

(d) logistic regression model using a training data period
from 1990 to 2008, with Lag2 as the only predictor and (e)LDA model using a training data period from 1990 to 2008, with Lag2 as the only predictor
provide the best results on this data, since they have the greatest overall fraction of correct predictions.


  
### (i)
KNN with k = 5
```{r}
train.X <- cbind(train$Lag2)
test.X <- cbind(test$Lag2)
train.Y <- train$Direction
set.seed(1)
knn.pred <- knn(train.X,test.X,train.Y, k = 5)
table(knn.pred, test$Direction)
mean(knn.pred == test$Direction)

```

KNN with k = 10

```{r}
train.X <- cbind(train$Lag2)
test.X <- cbind(test$Lag2)
train.Y <- train$Direction
set.seed(1)
knn.pred <- knn(train.X,test.X,train.Y, k = 10)
table(knn.pred, test$Direction)
mean(knn.pred == test$Direction)

```


LDA with all Lag variables
```{r}
library(MASS)
lda.fit <- lda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5, data = train)
lda.fit

preb <- predict(lda.fit, test, type = "response")
names(preb)
lda.class <- preb$class
table(lda.class, test$Direction)
mean(lda.class == test$Direction)

```

QDA with all Lag variables
```{r}
library(MASS)
qda.fit <- qda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5, data = train)
qda.fit

preb <- predict(qda.fit, test, type = "response")
names(preb)
qda.class <- preb$class
table(qda.class, test$Direction)
mean(qda.class == test$Direction)
```

QDA with all Lag variables and their interaction

```{r}
qda.fit <- qda(Direction ~ (Lag1 + Lag2 + Lag3 + Lag4 + Lag5)^2, data = train)
qda.fit

preb <- predict(qda.fit, test, type = "response")
names(preb)
qda.class <- preb$class
table(qda.class, test$Direction)
mean(qda.class == test$Direction)
```

Logistic regression with Lag1, Lag2, Volume and their interaction
```{r}

log.fit <- glm(Direction ~ (Lag1  + Lag2 + Volume)^2, 
               family = binomial(), data = Weekly)


glm.probs <- predict(log.fit,type = "response")
contrasts(Weekly$Direction)

glm.pred <- rep("Down", 1089)
glm.pred[glm.probs>0.5] <- "Up"
table(glm.pred, Weekly$Direction)
mean(glm.pred == Weekly$Direction)
```

We discover that the best prediction results are the qda model with all Lag variables, with its correct rate 0.644.

## Question 5 of Section 9.7 in ISLR

### (a)
```{r}
set.seed(37)
x1=runif (500) -0.5
x2=runif (500) -0.5
y=1*(x1^2-x2^2 > 0)
```


### (b)
```{r}
# Create a data frame
data1 <- data.frame(X1 = x1, X2 = x2, Class = as.factor(y))

# Plot the observations colored by class labels
library(ggplot2)
ggplot(data1, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  scale_color_manual(values = c("red", "blue")) +
  labs(x = "X1", y = "X2", color = "Class") +
  theme_minimal()

```

###  (c)

```{r}
log.fit <- glm(Class ~ X1 + X2, family = binomial(),data = data1)
summary(log.fit)


```

### (d)
```{r}

train <- data1[c(1:400),]
test <- data1[c(401:500),]
log.fit2 <- glm(Class ~ X1 + X2, data = train, family = binomial())
summary(log.fit2)


# Use the model to predict class labels for training data
train$predicted_class <- predict(log.fit2, data = train, type = "response") > 0.5
train$predicted_class[train$predicted_class == "FALSE"] <- 0
train$predicted_class[train$predicted_class == "TRUE"] <- 1
train$predicted_class <- as.factor(train$predicted_class)

# Plot the observations colored by predicted class labels
ggplot(train, aes(x = X1, y = X2, color = predicted_class)) +
  geom_point() +
  scale_color_manual(values = c("red", "blue")) +
  labs(x = "X1", y = "X2", color = "Predicted Class") +
  theme_minimal()

```

### (e)
```{r}

fit2 <- glm(Class ~ I(X1^2) + I(X1*X2) + log(X2^2)  ,data = data1, family = binomial())
summary(fit2)
```
### (f)
```{r}

fit3 <- glm(Class ~ I(X1^2) + I(X1*X2) + log(X2^2)  ,data = train, family = binomial())
summary(fit3)

train$predicted_class <- predict(fit3, data = train, type = "response") > 0.5
train$predicted_class[train$predicted_class == "FALSE"] <- 0
train$predicted_class[train$predicted_class == "TRUE"] <- 1
train$predicted_class <- as.factor(train$predicted_class)

# Plot the observations colored by predicted class labels
ggplot(train, aes(x = X1, y = X2, color = predicted_class)) +
  geom_point() +
  scale_color_manual(values = c("red", "blue")) +
  labs(x = "X1", y = "X2", color = "Predicted Class") +
  theme_minimal()


glm.probs2 <- predict(fit3, test, type = "response")
glm.pred2 <- rep("0", nrow(test))
glm.pred2[glm.probs2 > 0.5] <- 1
table(glm.pred2,test$Class)
mean(glm.pred2 == test$Class)
```


### (g)

```{r}

train <- data1[c(1:400),]
test <- data1[c(401:500),]

library(e1071)
svc.fit <- svm(Class ~.,data = train, kernel = "linear",cost = 5, scale = FALSE)
plot(svc.fit, train)
summary(svc.fit)




# Use the model to predict class labels for training data
train$predicted_class_svm <- predict(svc.fit, data = train)

# Plot the observations, colored by predicted class labels
ggplot(train, aes(x = X1, y = X2, color = predicted_class_svm)) +
  geom_point() +
  scale_color_manual(values = c("red", "blue")) +
  labs(x = "X1", y = "X2", color = "Predicted Class (SVM)") +
  theme_minimal()

```


### (h)

```{r}
train <- data1[c(1:400),]
test <- data1[c(401:500),] 
svm.fit <- svm(Class~.,data = train, kernel = "radial", cost = 5, gamma = 1)
plot(svm.fit, train)
summary(svm.fit)



# Use the model to predict class labels for training data
train$predicted_class_svm <- predict(svm.fit, data = train)

# Plot the observations, colored by predicted class labels
ggplot(train, aes(x = X1, y = X2, color = predicted_class_svm)) +
  geom_point() +
  scale_color_manual(values = c("red", "blue")) +
  labs(x = "X1", y = "X2", color = "Predicted Class (SVM)") +
  theme_minimal()


```


### (i)

When simulating data with a quadratic decision boundary, a logistic model with
quadratic transformations of the variables and an svm model with a quadratic
kernel both produce much better (and similar fits) than standard linear methods.





## Reproduction the Example in Section 9.3.3 of ISLR

First, we introduce the dataset and remove missing observations.

```{r}

data <- read.csv("C:/Users/Lenovo/Desktop/统计学习/Heart.csv")
data <- na.omit(data)

data$AHD[data$AHD == "Yes"] <- 1
data$AHD[data$AHD == "No"] <- 0

data$AHD <- as.numeric(data$AHD)
```

Then we randomly split it into 207 training and 90 test observations.

```{r}

set.seed(6)

train_indices <- sample(1:nrow(data), 207)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```

ROC curves for Heart data on training set.

```{r}

par(mfrow = c(1,2))


library(ROCR)

library(e1071)
svc.fit <- svm(AHD~.-X, data = train_data, kernel = "polynomial", d = 1, 
               cost = 1, scale = TRUE)
prob0 <- predict(svc.fit, train_data, type = "response")
predict0 <- prediction(prob0, train_data$AHD)
per0 <- performance(predict0, measure = "tpr", x.measure = "fpr")
plot(per0, col = "red")
abline(a = 0, b = 1,lty = 2)
legend("bottomright",  legend = c("Support Vector Classifier", "LDA" ),
       fill = c("red","blue"), cex = 0.6
)

library(MASS)
lda.fit <- lda(AHD~.-X,data = train_data)


lda.prob <- predict(lda.fit, train_data, type = "response")
lda.preb <- prediction(lda.prob$posterior[,2],train_data$AHD)
lda.per <- performance(lda.preb, measure = "tpr", x.measure = "fpr")
plot(lda.per, col = "blue", add = TRUE)





library(e1071)

plot(per0, col = "red")
legend("bottomright",  legend = c("Support Vector Classifier", "SVM γ = 0.1", 
                                  "SVM γ = 0.01", "SVM γ=0.001"),
       fill = c("red","blue","green", "black"), cex = 0.6
)

svm.fit <- svm(AHD ~.-X,data = train_data, kernel = "radial",
               cost = 1, scale = TRUE,  gamma = 0.1)
prob <- predict(svm.fit, train_data, type = "response")
predict <- prediction(prob, train_data$AHD)
per <- performance(predict, measure = "tpr", x.measure = "fpr")
plot(per, col = "blue", add = TRUE)
abline(a = 0, b = 1,lty = 2)


svm.fit2 <- svm(AHD ~.-X,data = train_data, kernel = "radial",
                cost = 1, scale = TRUE,  gamma = 0.01)
prob2 <- predict(svm.fit2, train_data, type = "response")
predict2 <- prediction(prob2, train_data$AHD)
per2 <- performance(predict2, measure = "tpr", x.measure = "fpr")
plot(per2, col = "green", add = TRUE)

svm.fit3 <- svm(AHD ~.-X,data = train_data, kernel = "radial",
                cost = 1, scale = TRUE,  gamma = 0.001)
prob3 <- predict(svm.fit3, train_data, type = "response")
predict3 <- prediction(prob3, train_data$AHD)
per3 <- performance(predict3, measure = "tpr", x.measure = "fpr")
plot(per3, col = "black", add = TRUE)

mtext("ROC curves for Heart data on training set", side = 3, line = -2, outer = TRUE, cex = 1.5)

```


ROC curves for Heart data on testing set.

```{r}

par(mfrow = c(1,2))


library(ROCR)

library(e1071)
svc.fit <- svm(AHD~.-X, data = train_data, kernel = "polynomial", d = 1, 
               cost = 1, scale = TRUE)
prob0 <- predict(svc.fit, test_data, type = "response")
predict0 <- prediction(prob0, test_data$AHD)
per0 <- performance(predict0, measure = "tpr", x.measure = "fpr")
plot(per0, col = "red")
abline(a = 0, b = 1,lty = 2)
legend("bottomright",  legend = c("Support Vector Classifier", "LDA" ),
       fill = c("red","blue"), cex = 0.6
)

library(MASS)
lda.fit <- lda(AHD~.-X,data = train_data)


lda.prob <- predict(lda.fit, test_data, type = "response")
lda.preb <- prediction(lda.prob$posterior[,2],test_data$AHD)
lda.per <- performance(lda.preb, measure = "tpr", x.measure = "fpr")
plot(lda.per, col = "blue", add = TRUE)





library(e1071)

plot(per0, col = "red")
legend("bottomright",  legend = c("Support Vector Classifier", "SVM γ = 0.1", 
                                  "SVM γ = 0.01", "SVM γ=0.001"),
       fill = c("red","blue","green", "black"), cex = 0.6
    )

svm.fit <- svm(AHD ~.-X,data = train_data, kernel = "radial",
               cost = 1, scale = TRUE,  gamma = 0.1)
prob <- predict(svm.fit, test_data, type = "response")
predict <- prediction(prob, test_data$AHD)
per <- performance(predict, measure = "tpr", x.measure = "fpr")
plot(per, col = "blue", add = TRUE)
abline(a = 0, b = 1,lty = 2)


svm.fit2 <- svm(AHD ~.-X,data = train_data, kernel = "radial",
               cost = 1, scale = TRUE,  gamma = 0.01)
prob2 <- predict(svm.fit2, test_data, type = "response")
predict2 <- prediction(prob2, test_data$AHD)
per2 <- performance(predict2, measure = "tpr", x.measure = "fpr")
plot(per2, col = "green", add = TRUE)

svm.fit3 <- svm(AHD ~.-X,data = train_data, kernel = "radial",
                cost = 1, scale = TRUE,  gamma = 0.001)
prob3 <- predict(svm.fit3, test_data, type = "response")
predict3 <- prediction(prob3, test_data$AHD)
per3 <- performance(predict3, measure = "tpr", x.measure = "fpr")
plot(per3, col = "black", add = TRUE)

mtext("ROC curves for Heart data on testing set", side = 3, line = -2, outer = TRUE, cex = 1.5)

```


